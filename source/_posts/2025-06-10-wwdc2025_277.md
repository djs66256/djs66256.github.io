---
title: 借助 SpeechAnalyzer 将先进的语音转文本功能引入 App
date: 2025-06-10 21:46:48
categories:
- wwdc2025
tags:
- wwdc2025
- ios
- ipados
- macos
- 机器学习与-ai
---
探索带来语音转文本功能的全新 speechanalyzer api。我们将了解这一 swift api 及其丰富的功能，这些功能为“备忘录”“语音备忘录”“手记”等 app 提供了支持。我们将深入探讨相关细节，了解语音转文本功能的运作方式，以及 speechanalyzer 和 speechtranscriber 如何助你构建精彩、实用的功能。你还将跟着视频学习如何通过编程将 speechanalyzer 和实时转录功能整合到 app 中。
<!--more-->

![视频封面](https://devimages-cdn.apple.com/wwdc-services/images/3055294D-836B-4513-B7B0-0BC5666246B0/9978/9978_wide_250x141_2x.jpg)
[视频地址](https://developer.apple.com/cn/videos/play/wwdc2025/277/)
> 此文章由AI生成，可能存在错误，如有问题，请联系[djs66256@163.com](djs66256@163.com)

# 通过 SpeechAnalyzer 为 App 引入先进的语音转文本功能

## 引言

在 iOS 18 中，苹果推出了全新的 SpeechAnalyzer API，这是一个强大的语音转文本解决方案，为开发者提供了与系统应用（如备忘录、语音备忘录和手记）相同的核心技术。这项创新技术不仅提升了转录速度和准确性，还支持本地端处理，确保了用户隐私。

## SpeechAnalyzer API 概述

### 与传统技术的比较

SpeechAnalyzer 取代了 iOS 10 引入的 SFSpeechRecognizer，提供了更先进的语音识别能力。传统技术主要用于短文本听写，而新 API 专为处理长距离音频场景（如讲座、会议和对话）优化，具有以下显著优势：

- 更快的处理速度
- 更强的适应性
- 更好的长音频处理能力
- 本地端处理确保隐私安全

### API 架构设计

SpeechAnalyzer 采用模块化设计，核心类是 SpeechAnalyzer 和 SpeechTranscriber。其工作流程如下：

1. 创建分析器实例
2. 添加转录模块
3. 接收音频缓冲区
4. 异步返回处理结果

这种设计充分利用了 Swift 的异步序列机制，将音频输入和结果输出解耦，所有操作都基于精确的音频时间线执行。

## 核心功能与使用方式

### 转录结果类型

SpeechAnalyzer 提供两种转录结果：

- **易变结果(volatile results)**：近乎实时呈现但准确性较低
- **确定性结果**：随着获取更多上下文音频，模型会逐步优化并最终输出

开发者可以通过简单的代码实现基本转录功能：

```swift
let transcriber = SpeechTranscriber(locale: locale, preset: .offlineTranscription)
async let transcriptionFuture = try transcriber.results
    .reduce("") { str, result in str + result.text }

let analyzer = SpeechAnalyzer(modules: [transcriber])
if let lastSample = try await analyzer.analyzeSequence(from: file) {
    try await analyzer.finalizeAndFinish(through: lastSample)
} else {
    await analyzer.cancelAndFinishNow()
}
    
return try await transcriptionFuture
```

### SpeechTranscriber 模式

SpeechTranscriber 由苹果全新研发的模型驱动，具有以下特点：

- 支持多语言（持续增加中）
- 适用于除 watchOS 外的所有平台
- 模型自动更新机制
- 不增加应用下载大小或存储占用

对于不支持的语言或设备，API 还提供了 DictationTranscriber 作为备用方案。

## 实战应用：构建实时转录功能

### 实现步骤

1. **配置 SpeechTranscriber**

```swift
func setUpTranscriber() async throws {
    transcriber = SpeechTranscriber(locale: Locale.current,
                                    transcriptionOptions: [],
                                    reportingOptions: [.volatileResults],
                                    attributeOptions: [.audioTimeRange])
}
```

2. **设置 SpeechAnalyzer 和音频格式**

```swift
analyzer = SpeechAnalyzer(modules: [transcriber])
self.analyzerFormat = await SpeechAnalyzer.bestAvailableAudioFormat(compatibleWith: [transcriber])
```

3. **处理转录结果**

```swift
recognizerTask = Task {
    do {
        for try await case let result in transcriber.results {
            let text = result.text
            if result.isFinal {
                finalizedTranscript += text
                volatileTranscript = ""
                updateStoryWithNewText(withFinal: text)
                print(text.audioTimeRange)
            } else {
                volatileTranscript = text
                volatileTranscript.foregroundColor = .purple.opacity(0.4)
            }
        }
    } catch {
        print("语音识别失败")
    }
}
```

### 音频处理

音频输入处理包括权限请求和 AVAudioSession 配置：

```swift
func record() async throws {
    self.story.url.wrappedValue = url
    guard await isAuthorized() else {
        print("用户拒绝麦克风权限")
        return
    }
#if os(iOS)
    try setUpAudioSession()
#endif
    try await transcriber.setUpTranscriber()
            
    for await input in try await audioStream() {
        try await self.transcriber.streamAudioToTranscriber(input)
    }
}
```

## 与 Apple Intelligence 结合

SpeechTranscriber 的高准确性使其成为 Apple Intelligence 处理的理想输入源。开发者可以利用 FoundationModels API 进行后续处理，如自动生成内容摘要或标题。

## 结论

SpeechAnalyzer API 为开发者提供了强大而灵活的语音转文本解决方案，使得构建类似备忘录这样功能丰富的应用变得简单高效。新模型的速度、准确性和隐私保护特性，加上 Swift 的现代异步编程模型，为开发者创造了绝佳的开发体验。

更多技术细节和示例应用代码，开发者可以参考官方文档和示例项目。

## 相关视频

[使用个人和自定义声音扩展语音合成](https://developer.apple.com/videos/play/wwdc2023/10033)

## 文档

[Speech](https://developer.apple.com/documentation/Speech)
