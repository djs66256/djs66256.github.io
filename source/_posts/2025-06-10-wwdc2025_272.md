---
title: 使用 Vision 框架读取文档
date: 2025-06-10 21:46:48
categories:
- wwdc2025
tags:
- wwdc2025
- ios
- ipados
- macos
- visionos
- 机器学习与-ai
---
了解 vision 框架的最新进展。我们将介绍 recognizedocumentsrequest，并介绍如何使用该工具读取文本行并将其分组为段落、读取表格等。此外，我们将深入探讨相机镜头污渍检测，以及如何在照片图库或你自己的相机拍摄管道中识别可能有污渍的图像。
<!--more-->

![视频封面](https://devimages-cdn.apple.com/wwdc-services/images/3055294D-836B-4513-B7B0-0BC5666246B0/9973/9973_wide_250x141_2x.jpg)
[视频地址](https://developer.apple.com/cn/videos/play/wwdc2025/272/)
> 此文章由AI生成，可能存在错误，如有问题，请联系[djs66256@163.com](djs66256@163.com)

# Vision框架新功能解析：文档读取与镜头污渍检测

在WWDC 2024上，苹果Vision框架团队工程师Megan Williams介绍了两项重要的新功能：RecognizeDocumentsRequest文档结构识别和DetectLensSmudgeRequest镜头污渍检测，以及手部姿态检测模型的更新。这些新功能为开发者提供了更强大的计算机视觉处理能力。

## 结构化文档识别：RecognizeDocumentsRequest

传统的RecognizeTextRequest只能提取文本行，而全新的RecognizeDocumentsRequest则能够识别文档中的结构化元素。该API支持26种语言的文本识别，能够：

- 检测表格、列表等文档结构
- 将文本行智能分组为段落
- 识别二维码等机器可读代码
- 提取电子邮件、电话号码等重要信息

### 实用示例：签到表解析

以一个商店顾客签到表为例，开发者可以轻松提取表格中的联系人信息。通过表格的层次结构，可以逐行读取姓名、邮箱和电话号码。

```
/// 处理图像并返回检测到的第一个表格
func extractTable(from image: Data) async throws -> DocumentObservation.Container.Table {
    let request = RecognizeDocumentsRequest()
    let observations = try await request.perform(on: image)
    guard let document = observations.first?.document else {
        throw AppError.noDocument
    }
    guard let table = document.tables.first else {
        throw AppError.noTable
    }
    return table
}
```

### 文本内容处理方式

文档内容提供多种查看方式：
- `transcript`: 将所有文本作为单个字符串
- `lines`: 以文本行数组形式呈现
- `detectedData`: 检测特殊字符串(邮箱、电话等)

```
/// 从表格中提取姓名、邮箱和电话号码生成联系人列表
private func parseTable(_ table: DocumentObservation.Container.Table) -> [Contact] {
    var contacts = [Contact]()
    for row in table.rows {
        guard let firstCell = row.first else { continue }
        let name = firstCell.content.text.transcript
        
        var detectedPhone: String? = nil
        var detectedEmail: String? = nil
        
        for cell in row.dropFirst() {
            let allDetectedData = cell.content.text.detectedData
            for data in allDetectedData {
                switch data.match.details {
                case .emailAddress(let email):
                    detectedEmail = email.emailAddress
                case .phoneNumber(let phoneNumber):
                    detectedPhone = phoneNumber.phoneNumber
                default: break
                }
            }
        }
        if let email = detectedEmail {
            let contact = Contact(name: name, email: email, phoneNumber: detectedPhone)
            contacts.append(contact)
        }
    }
    return contacts
}
```

## 相机镜头污渍检测

DetectLensSmudgeRequest能够识别因镜头污渍导致的低质量照片。该API会生成一个0-1之间的置信度分数，开发者可以设置阈值来筛选可用图像。

```
let request = DetectLensSmudgeRequest()
let observations = try await request.perform(on: image)
if let observation = observations.first, observation.confidence > 0.9 {
    // 图像可能存在污渍
}
```

需要注意的是，某些特殊情况如运动模糊或云雾照片也可能被误判为污渍图像。建议结合其他Vision API如DetectFaceCaptureQualityRequest或CalculateImageAestheticScoresRequest共同评估图像质量。

## 手部姿态检测更新

Vision对手部姿态检测模型进行了升级，新模型具有：
- 更高的精度
- 更小的内存占用
- 更低的延迟

虽然仍检测21个关节位置，但新模型的关节定位与旧模型有所不同。已训练手部姿态分类器的开发者建议重新训练模型以获得最佳准确性。

## 总结

Vision框架的新功能为开发者提供了：
1. 强大的文档结构解析能力(RecognizeDocumentsRequest)
2. 图像质量控制工具(DetectLensSmudgeRequest)
3. 更精确的手部姿态检测模型

这些更新将使开发者在处理文档扫描、图像质量控制和手势交互等场景时获得更出色的体验和效果。

## 相关视频

[探索 Apple 平台上的机器学习和 AI 框架](https://developer.apple.com/videos/play/wwdc2025/360)
[探索 Vision 框架中的 Swift 增强功能](https://developer.apple.com/videos/play/wwdc2024/10163)
[在 Vision 中探索 3D 人体位姿和人像分隔](https://developer.apple.com/videos/play/wwdc2023/111241)
[在 Vision 中检测动物体态](https://developer.apple.com/videos/play/wwdc2023/10045)

## 文档资源

[Classifying Images with Vision and Core ML](https://developer.apple.com/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml)
[Vision](https://developer.apple.com/documentation/Vision)
