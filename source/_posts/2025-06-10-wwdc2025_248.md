---
title: 探索设备端基础模型的提示设计和安全
date: 2025-06-10 21:46:48
categories:
- wwdc2025
tags:
- wwdc2025
- ios
- ipados
- macos
- 设计
---
设计充分发挥 foundation models 框架优势的生成式 ai 体验。首先我们将展示如何为 apple 智能核心的设备端大语言模型设计提示。然后，我们将介绍 ai 安全方面的关键理念，并提供切实可行的具体策略来助你打造安全、可靠且令人愉悦的生成式 ai 功能。
<!--more-->

![视频封面](https://devimages-cdn.apple.com/wwdc-services/images/3055294D-836B-4513-B7B0-0BC5666246B0/10049/10049_wide_250x141_2x.jpg)
[视频地址](https://developer.apple.com/cn/videos/play/wwdc2025/248/)
> 此文章由AI生成，可能存在错误，如有问题，请联系[djs66256@163.com](djs66256@163.com)

# 探索设备端基础模型的提示设计与安全

## 引言

在WWDC演讲中，Apple详细介绍了如何为设备端大语言模型（LLM）设计高效安全的提示（prompt），以及如何构建注重AI安全的生成式AI体验。本文将深入解析这些关键内容，帮助开发者充分利用Foundation Models框架的能力。

## 设备端LLM的设计策略

Apple的设备端语言模型虽然经过优化和压缩（约30亿参数），仍能处理多种常见语言任务：

- 摘要生成
- 分类
- 多轮对话
- 文本创作与修订
- 文本标签生成

与云端数千亿参数的大模型相比，设备端LLM存在一些重要限制：

1. **任务复杂度**：复杂推理任务需分解为简单步骤
2. **数学运算**：建议使用传统代码处理
3. **代码生成**：未经优化，应避免使用
4. **世界知识**：训练数据时效性有限，不可完全依赖其提供事实

开发者需特别注意"幻觉"现象——模型对未知知识可能完全虚构答案。在需要准确事实的场合，建议：

```swift
// 最佳实践：在提示中写入已验证信息
let verifiedPrompt = "基于以下已验证信息：(百吉饼主要成分是面粉、水、酵母和盐)，请描述原味百吉饼的特点"
```

## 提示工程最佳实践

提示工程是发挥模型潜力的关键。Apple分享了几个实用技巧：

1. **控制输出长度**：
   - "只写一段"
   - "用三句话"
   - "详细描述"

2. **风格控制**：
   ```swift
   let stylePrompt = "扮演用莎士比亚英语说话的狐狸，写一篇日记"
   ```

3. **清晰指令设计**：
   - 单一明确任务
   - 提供少量示例(少于5个)
   - 使用"DO NOT"终止不良输出

Xcode的Playground功能是实验提示的理想工具：

```swift
#Playground
// 尝试不同提示并实时查看结果
let testPrompt = "生成一个适合6岁儿童的太空冒险故事"
```

## 指令与提示的协作

指令作为Foundation Models框架的特殊提示类型，能持久影响模型行为：

```swift
// 设置全局指令
let instruction = "你是一个乐于助人的助手，专门为青少年生成适合的恐怖故事"

// 后续提示将遵循该指令
let followUpPrompt = "写一首关于百吉饼的诗" // 输出将是恐怖风格的百吉饼诗
```

## AI安全的多层防护策略

Apple为Foundation Models框架构建了完整的安全体系：

1. **内置安全防护**：拦截有害的输入/输出
2. **安全指令**：优先于普通提示
3. **输入控制**：谨慎处理用户输入
4. **场景缓解**：针对应用特性定制防护

安全错误处理示例：

```swift
do {
    try await model.generate(with: prompt)
} catch {
    // 对用户发起的功能提供适当反馈
    showAlert("内容无法生成，请尝试其他提示")
}
```

## 评估与测试方法

开发生成式AI功能时，建议：

1. 构建质量和安全测试数据集
2. 设计自动化测试方案
3. 人工检查关键场景
4. 异常路径测试
5. 持续监控改进

## 结论

通过合理运用提示工程技术和多层安全防护，开发者可以在设备端创建既强大又安全的生成式AI体验。Apple的Foundation Models框架提供了必要的工具和防护，而开发者需要针对具体应用场景完善设计和测试。

## 相关文档

[人机界面指南：生成式 AI](https://developer.apple.com/design/human-interface-guidelines/generative-ai)
[人机界面指南：机器学习](https://developer.apple.com/design/human-interface-guidelines/machine-learning)
[提升生成模型输出的安全性](https://developer.apple.com/documentation/FoundationModels/improving-safety-from-generative-model-output)
