---
title: 了解 Apple 沉浸视频技术
date: 2025-06-10 21:46:48
categories:
- wwdc2025
tags:
- wwdc2025
- visionos
- 音频和视频
---
探索 apple 沉浸视频和 apple 空间音频格式技术的功能，以打造真正的沉浸式体验。了解新的 immersivemediasupport 框架，该框架可读取和写入必要的元数据来实现 apple 沉浸视频。了解在单独的文件中编码和发布 apple 沉浸视频内容以通过 hls 进行播放或流媒体播放时应遵循的准则。

为了充分从这个讲座中获益，建议你先观看“探索 visionos 的视频体验”。
<!--more-->

![视频封面](https://devimages-cdn.apple.com/wwdc-services/images/3055294D-836B-4513-B7B0-0BC5666246B0/10238/10238_wide_250x141_2x.jpg)
[视频地址](https://developer.apple.com/cn/videos/play/wwdc2025/403/)
> 此文章由AI生成，可能存在错误，如有问题，请联系[djs66256@163.com](djs66256@163.com)

## Apple 沉浸式视频技术深度解析：从元数据到空间音频

在 WWDC26 上，Apple 展示了其最新的沉浸式视频技术，为开发者提供了打造深度沉浸体验的全新工具。本文将详细介绍这些技术的核心要素，包括视频元数据处理、文件格式规范以及创新的空间音频系统。

### 技术概览

Apple 沉浸式视频代表了 Apple Vision Pro 上的终极视频体验，结合了高保真视频与全沉浸音频，创造出令人叹为观止的临场感。这项技术要求使用特殊校准的专业摄像机（如 Blackmagic URSA Cine Immersive）来捕捉内容，这些摄像机出厂时已经过精确校准，能够记录每个立体镜头的曲率数据。

macOS 和 visionOS 26 引入了全新的 Immersive Media Support 框架，为开发者提供了读写必要元数据、创建自定义工作流以及在编辑过程中预览内容的能力。

### 沉浸式视频元数据架构

实现沉浸体验的核心在于元数据系统。整个架构包含两个关键组成部分：

1. **VenueDescriptor**：描述拍摄场景中的摄像机组合信息，包括：
   - 摄像机引用和视图模型
   - AIMEData（Apple Immersive Media Embedded）引用
   - 边缘遮罩和原点位置等校准数据
   - 自定义背景环境添加功能

2. **PresentationCommand**：表示定时动态元数据命令，用于处理：
   - 镜头翻转（shot flop）自动镜像
   - 动态渲染的淡入淡出效果
   - 其他帧级调整

这些元数据会被混流到最终 QuickTime 文件中，确保每帧都能获得正确的投影处理。

### AIVU 文件处理

Apple 推出了专用的 Apple Immersive Video Universal（AIVU）文件格式，作为沉浸式内容的容器。开发者可以通过以下方式处理这些文件：

**读取流程**：
1. 使用 AVAsset 读取元数据
2. 通过 quickTimeMetadataAIMEData 标识符过滤出 AIMEData
3. 转换为 VenueDescriptor 对象
4. 使用 quickTimeMetadataPresentationImmersiveMedia 标识符获取同步元数据组
5. 解码为 PresentationDescriptor

**写入流程**：
1. 确保视频资产使用 AppleImmersiveVideo 投影类型
2. 通过 AVAssetWriter 写入 VenueDescriptor 和 PresentationCommand
3. 使用 AIVUValidator 验证文件完整性

### 内容发布规范

通过 HLS 流式传输沉浸式内容时，开发者需注意以下技术规格：

- **视频**：支持 4320×4320 单眼分辨率，90 帧/秒 MV-HEVC 格式
- **色彩空间**：P3-D65-PQ
- **码率建议**：平均 25-100 Mbps，峰值 50-150 Mbps
- **HLS 要求**：
  - 版本 12+
  - 指向 AIME 文件的 venue description data ID
  - 内容类型标记为 fully immersive
  - 使用 APAC 音频编码

### 空间音频创新

Apple 推出了两套音频技术来增强沉浸感：

1. **ASAF（Apple Spatial Audio Format）**：
   - 基于广播 Wave 文件格式
   - 结合线性 PCM 与空间元数据
   - 支持多点源和高阶 Ambisonics

2. **APAC（Apple Positional Audio Codec）**：
   - 流媒体专用编码格式
   - 最低仅需 64 kbps 即可实现沉浸音频
   - 支持各种音频特性（对象、Ambisonics、对话等）

这些音频技术能与视频完美同步，根据观众位置和方向实时调整，创造真正的3D音频体验。

### 开发资源

开发者可以通过以下资源深入了解这些技术：

**相关视频**：
- [了解 Apple Projected Media Profile](https://developer.apple.com/videos/play/wwdc2025/297)
- [探索 visionOS 的视频体验](https://developer.apple.com/videos/play/wwdc2025/304)
- [支持 visionOS App 播放沉浸视频](https://developer.apple.com/videos/play/wwdc2025/296)

**文档**：
- [Immersive Media Support](https://developer.apple.com/documentation/ImmersiveMediaSupport)
- [HTTP Live Streaming (HLS) authoring specification](https://developer.apple.com/documentation/HTTP-Live-Streaming/hls-authoring-specification-for-apple-devices)

随着这些技术的推出，开发者现在拥有了打造真正沉浸式体验所需的全部工具，期待看到创意社区利用这些技术创造出令人惊叹的作品。
